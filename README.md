# coreML
~~*Playing around with CoreML*~~

Use CoreML and SqueezeNet model to detect what is on a picture. Tap the screen to take a picture and analyse it. The app uses a speech synthetizer to speak what is detected in the image

## _stack
* Swift 5
* AVFoundation
* CoreML
* Vision
* SqueezeNet (image classification model)
* Speech Synthetizer (to speak what is identified in the image)

## Screenshots
<img src="https://raw.githubusercontent.com/kilyan-s/coreML/master/Screenshot/0.PNG" alt="Camera screen" width="200"/> <img src="https://raw.githubusercontent.com/kilyan-s/coreML/master/Screenshot/1.PNG" alt="Object detected in picture" width="200"/>
